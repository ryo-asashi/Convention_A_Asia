{
  "hash": "083d52124b88ee02429e576504b2086e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Surrogate Modeling with MID in R\"\n---\n\n## Introduction\n\nIn modern actuarial science, there is an inherent tension between predictive accuracy and model transparency.\nWhile ensemble tree-based models like **Gradient Boosting Machines (GBMs)** frequently outperform traditional **Generalized Linear Models (GLMs)**, their \"black-box\" nature presents significant hurdles for model governance, regulatory compliance, and price filing.\n\nThis notebook demonstrates a solution using **Maximum Interpretation Decomposition (MID)** via the `{midr}` and `{midnight}` packages in R.\n\n### What is MID?\n\nMID is a functional decomposition framework that acts as a high-fidelity surrogate for complex models.\nIt deconstructs a black-box prediction function $f(\\mathbf{x})$ into several interpretable components: intercept $g_\\emptyset$, main effects $g_j(x_j)$, and interaction effects $g_{jk}(x_j, x_k)$.\nThe prediction is represented as the following additive structure:\n\n$$\nf(\\mathbf{x}) = g_\\emptyset + \\sum_{j} g_j(x_{j}) + \\sum_{j < k} g_{jk}(x_{j},\\;x_{k}) + \\dots + g_D(\\mathbf{x})\n$$\n\nTo ensure the uniqueness and interpretability of each component, MID imposes vanishing conditional expectation constraints:\n\n$$\n\\begin{aligned}\n\\mathbf{E}\\left[g_j(X_j)\\right] &= 0 \\\\\n\\mathbf{E}\\left[g_{jk}(X_j, X_k) \\mid X_j = x_j\\right] &= 0 \\quad (\\forall x_j) \\\\\n\\mathbf{E}\\left[g_{jk}(X_j, X_k) \\mid X_k = x_k\\right] &= 0 \\quad (\\forall x_k)\n\\end{aligned}\n$$\n\nBy replicating a black-box model with this structured approach, we can quantify the \"uninterpreted\" variance (captured by $g_D(\\mathbf{x})$) and derive a representation that captures the superior predictive power of machine learning without sacrificing actuarial clarity.\n\n### Setting Up\n\nWe begin by setting up the environment and loading the necessary libraries.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# data manipulation\nlibrary(arrow)\nlibrary(dplyr)\n\n# predictive modeling\nlibrary(gam)\nlibrary(lightgbm)\n\n# surrogate modeling\nlibrary(midr)\nlibrary(midnight)\n\n# visualization\nlibrary(ggplot2)\nlibrary(gridExtra)\n\n# load training and testin datasets\ntrain <- read_parquet(\"../data/train.parquet\")\ntest  <- read_parquet(\"../data/test.parquet\")\n```\n:::\n\n\n\n\nA key component of our evaluation is the **Weighted Mean Poisson Deviance** defined as follows.\n\n$$\nL(\\mathbf{y}, \\hat{\\mathbf{y}}, \\mathbf{w}) = \\frac{2 \\sum_{i=1}^n w_i \\left( y_i \\log(y_i/\\hat{y}_i) - (y_i - \\hat{y}_i) \\right)}{\\sum_{i=1}^n w_i}\n$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# define loss function\nmean_poisson_deviance <- function(\n    y_true, y_pred, sample_weight = rep(1, length(y))\n  ) {\n  stopifnot(all(y_pred > 0))\n  resid <- ifelse(y_true > 0, y_true * log(y_true / y_pred), 0)\n  resid <- resid - y_true + y_pred\n  2 * sum(resid * sample_weight) / sum(sample_weight)\n}\n```\n:::\n\n\n## The Interpretable Baseline: GAM\n\nWe first fit a GAM to establish a transparent benchmark.\nSince GAMs are additive by design, they provide a \"ground truth\" model structure to be recovered by the functional decomposition.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_gam <- gam(\n  Frequency ~ s(VehPower) + s(VehAge) + s(DrivAge) + s(LogDensity) +\n              VehBrand + VehGas + Region,\n  data = train,\n  weights = Exposure,\n  family = quasipoisson(link = \"log\")\n)\n\nsummary(fit_gam)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall: gam(formula = Frequency ~ s(VehPower) + s(VehAge) + s(DrivAge) + \n    s(LogDensity) + VehBrand + VehGas + Region, family = quasipoisson(link = \"log\"), \n    data = train, weights = Exposure)\nDeviance Residuals:\n    Min      1Q  Median      3Q     Max \n-0.7606 -0.3400 -0.2556 -0.1401 10.7719 \n\n(Dispersion Parameter for quasipoisson family taken to be 1.7241)\n\n    Null Deviance: 86471.6 on 338994 degrees of freedom\nResidual Deviance: 84868.97 on 338966 degrees of freedom\nAIC: NA \n\nNumber of Local Scoring Iterations: NA \n\nAnova for Parametric Effects\n                  Df Sum Sq Mean Sq  F value    Pr(>F)    \ns(VehPower)        1     45   45.32  26.2882 2.942e-07 ***\ns(VehAge)          1     35   34.96  20.2764 6.704e-06 ***\ns(DrivAge)         1    320  319.82 185.4987 < 2.2e-16 ***\ns(LogDensity)      1    531  531.36 308.1989 < 2.2e-16 ***\nVehBrand           5     91   18.14  10.5199 4.072e-10 ***\nVehGas             1     56   55.72  32.3196 1.309e-08 ***\nRegion             6     73   12.15   7.0499 1.606e-07 ***\nResiduals     338966 584406    1.72                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nAnova for Nonparametric Effects\n              Npar Df Npar F     Pr(F)    \n(Intercept)                               \ns(VehPower)         3  1.320    0.2659    \ns(VehAge)           3 11.223 2.328e-07 ***\ns(DrivAge)          3 83.378 < 2.2e-16 ***\ns(LogDensity)       3  1.052    0.3684    \nVehBrand                                  \nVehGas                                    \nRegion                                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# evaluate fitted model\npred_fit_gam <- predict(fit_gam, test, type = \"response\")\n\ndeviance <- mean_poisson_deviance(\n  y_true = test$Frequency,\n  y_pred = pred_fit_gam,\n  sample_weight = test$Exposure\n)\ncat(\"Mean Poisson Deviance:\", deviance)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMean Poisson Deviance: 0.4679338\n```\n\n\n:::\n:::\n\n\n### Surrogate Modeling\n\nWe apply the `interpret()` function to the GAM.\nThis step serves as a sanity check: if MID is effective, it should perfectly replicate the predictive behavior of the original GAM.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmid_gam <- interpret(\n  Frequency ~ VehPower + VehAge + DrivAge + LogDensity +\n              VehBrand + VehGas + Region,\n  data = train,\n  weights = Exposure,\n  link = \"log\",\n  model = fit_gam\n)\n\nsummary(mid_gam)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\ninterpret(formula = Frequency ~ VehPower + VehAge + DrivAge +\n LogDensity + VehBrand + VehGas + Region, data = train, model = fit_gam,\n weights = Exposure, link = \"log\")\n\nLink: log\n\nUninterpreted Variation Ratio:\n   working   response \n3.7577e-05 2.5365e-05 \n\nWorking Residuals:\n        Min          1Q      Median          3Q         Max \n-0.01324336 -0.00069460 -0.00004683  0.00057250  0.01822450 \n\nEncoding:\n           main.effect\nVehPower     linear(9)\nVehAge      linear(18)\nDrivAge     linear(25)\nLogDensity  linear(25)\nVehBrand     factor(6)\nVehGas       factor(2)\nRegion       factor(7)\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# evaluate fitted surrogate\npred_mid_gam = predict(mid_gam, test, type = \"response\")\n\ndeviance <- mean_poisson_deviance(\n  y_true = test$Frequency,\n  y_pred = pred_mid_gam,\n  sample_weight = test$Exposure\n)\ncat(\"Mean Poisson Deviance:\", deviance)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMean Poisson Deviance: 0.4679292\n```\n\n\n:::\n:::\n\n\n### Model Fidelity\n\nTo assess model **fidelity**, i.e., how closely the surrogate replicates the black-box, we calculate the **uninterpreted variation ratio** $\\mathbf{U}$.\n\n$$\n\\mathbf{U}(f,g) = \\frac{\\sum_{i=1}^n (f(x_i) - g(x_i))^2}{\\sum_{i=1}^n (f(x_i) - \\bar{f})^2}, \\quad \\text{where } \\bar{f} = \\frac{1}{n}\\sum_{i=1}^n f(x_i)\n$$\n\nThis metric represents the proportion of the black-box model's variance that is not captured by the additive components of the MID model.\nThe **R-squared score**, $\\mathbf{R}^2(f,g) = 1 - \\mathbf{U}(f,g)$, is a standard measure for this purpose. It is important to note that this $\\mathbf{R}^2$ measures the fidelity to the black-box model, not the predictive accuracy relative to the ground truth observations.\n\nIn the `{midr}` package, the summary output includes this ratio calculated on the training set.\nFor models with non-linear links (e.g., Poisson regression), the \"working\" ratio is computed on the scale of the link function (e.g., $\\log$ scale).\n\nTo rigorously confirm the model fidelity, it is recommended to evaluate these metrics on a separate testing set.\nThis ensures that the surrogate model is not just over-fitting the training predictions but has truly captured the underlying functional structure.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# calculate R-squared on testing dataset\nR2_mid <- weighted.loss(\n  x = log(pred_fit_gam),\n  y = log(pred_mid_gam),\n  w = test$Exposure,\n  method = \"r2\"\n)\n\ncat(sprintf(\"R-squared: %.6f\", R2_mid))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nR-squared: 0.999963\n```\n\n\n:::\n:::\n\n\nAs shown by the high $\\mathbf{R}^2$ score, the MID surrogate achieves near-perfect fidelity.\nThis level of agreement justifies using the MID components (main effects and interactions) as a reliable lens through which to interpret the original black-box modelâ€™s behavior.\n\n### Feature Effects\n\nVisualizing the functional behavior of each component allows for a direct comparison between the MID surrogate's decomposition and the original GAM's structure.\n\n- MID Surrogate\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# main effects of MID surrogate\npar.midr(mfrow = c(2, 4))\nmid.plots(mid_gam, engine = \"graphics\", ylab = \"Main Effect\")\n```\n\n::: {.cell-output-display}\n![](demo_r_files/figure-html/effects_mid_gam-1.png){width=672}\n:::\n:::\n\n\n- Original GAM\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# feature effects of GAM\npar.midr(mfrow = c(2, 4))\ntermplot(fit_gam)\n```\n\n::: {.cell-output-display}\n![](demo_r_files/figure-html/effects_fit_gam-1.png){width=672}\n:::\n:::\n\n\nFurthermore, we can visualize the joint effects of feature pairs as 3D prediction surfaces using the S3 method for the `persp()` function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar.midr(mar = c(1, 0, 1, 0), mfrow = c(1, 2))\npersp(mid_gam, \"DrivAge:LogDensity\", theta = 45, phi = 40)\npersp(mid_gam, \"LogDensity:Region\", theta = -45, phi = 40)\n```\n\n::: {.cell-output-display}\n![](demo_r_files/figure-html/persp_mid_gam-1.png){width=672}\n:::\n:::\n\n\n### Effect Importance\n\nBeyond simple plots for feature effects, `{midr}` provides a suite of diagnostic tools.\nFirst, the **Effect Importance** of a term $j$ is defined as the mean absolute contribution of that term across the population:\n\n$$\n\\text{Importance}_j = \\mathbf{E} \\left[ | g_j(X_j) | \\right] \\approx \\frac{1}{n} \\sum_{i=1}^n | g_j(x_{ij}) |\n$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nimp_gam <- mid.importance(mid_gam, data = train, max.nrow = 2000)\ngrid.arrange(\n  nrow = 1, widths = c(5, 4),\n  ggmid(imp_gam, fill = \"steelblue\") +\n    labs(title = \"Effect Importance\",\n         subtitle = \"Average absolute effect per feature\"),\n  ggmid(imp_gam, type = \"beeswarm\", theme = \"mako@div\") +\n    labs(title = \"\",\n         subtitle = \"Distribution of effect per feature\") +\n    scale_y_discrete(labels = NULL) +\n    theme(legend.position = \"none\")\n)\n```\n\n::: {.cell-output-display}\n![](demo_r_files/figure-html/imp_gam-1.png){width=672}\n:::\n:::\n\n\nFor interaction terms, the importance is similarly calculated using $g_{jk}(X_j, X_k)$.\nThis metric allows us to rank features by their average influence on the model's predictions.\n\n### Conditional Expectation\n\nSecond, we can explore **Individual Conditional Expectations (ICE)**.\nIn the MID framework, the ICE for a feature $j$ and a specific observation $i$ is the expected value of the prediction as $X_j$ varies, while keeping other features fixed at their observed values $\\mathbf{x}_{\\setminus j}^{(i)}$:\n\n$$\n\\text{ICE}_j^{(i)}(x) = g_\\emptyset + g_j(x) + \\sum_{k \\neq j} g_{jk}(x, x_{ik})\n$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nice_gam_link <- mid.conditional(mid_gam, type = \"link\", variable = \"DrivAge\")\nice_gam <- mid.conditional(mid_gam, variable = \"DrivAge\")\ngrid.arrange(\n  nrow = 1,\n  ggmid(ice_gam_link, var.color = LogDensity) +\n    theme(legend.position = \"bottom\") +\n    labs(y = \"Linear Predictor\",\n         title = \"Conditional Expectation\",\n         subtitle = \"Change in linear predictor\"),\n  ggmid(ice_gam, type = \"centered\", var.color = LogDensity) +\n    theme(legend.position = \"bottom\") +\n    labs(y = \"Prediction\", title = \"\",\n         subtitle = \"Centered change in original scale\")\n)\n```\n\n::: {.cell-output-display}\n![](demo_r_files/figure-html/ice_gam-1.png){width=672}\n:::\n:::\n\n\nUnlike standard black-box models, MID's low-order structure allows us to compute these expectations efficiently and interpret the variation across curves (the \"thickness\" of the ICE plot) as a direct consequence of specified interaction terms $g_{jk}$.\n\n### Additive Attribution\n\nThird, we perform instance-level explanation through an Additive Breakdown of the prediction.\nFor any single observation $\\mathbf{x}$, the MID surrogate's prediction $g(\\mathbf{x})$ is decomposed into the exact sum of its functional components:\n\n$$\ng(\\mathbf{x}) = \\underbrace{g_\\emptyset}_{\\text{Intercept}} + \\underbrace{\\sum_{j} g_j(x_j)}_{\\text{Main Effects}} + \\underbrace{\\sum_{j < k} g_{jk}(x_j, x_k)}_{\\text{Interactions}}\n$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(42)\nrow_ids <- sort(sample(nrow(train), 4))\nbd_list <- lapply(\n  row_ids,\n  function(x) {\n    res <- mid.breakdown(mid_gam, train, row = x,\n                         format = list(LogDensity = \"%.2f\"))\n    structure(res, row_id = x)\n  }\n)\nbd_plots <- lapply(\n  bd_list, function(x) {\n    label <- paste0(\"Breakdown of Row \", attr(x, \"row_id\"))\n    ggmid(x, theme = \"shap\") +\n      labs(x = NULL, subtitle = label) +\n      theme(legend.position = \"none\")\n  }\n)\ngrid.arrange(grobs = bd_plots)\n```\n\n::: {.cell-output-display}\n![](demo_r_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\nBy visualizing these contributions in a waterfall plot, we can identify which specific risk factors or interaction effects drove the prediction for a particular instance, such as a high-risk policyholder.\n\n## The Black-Box: LightGBM\n\nWhile GAMs are transparent, GBMs such as **LightGBM** often yield superior predictive power by capturing high-order interactions.\nHowever, this accuracy comes at the cost of being a black box.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# hold out validation dataset\nvalid_idx <- seq_len(floor(nrow(train) * 0.2))\n\n# create datasets for training\ndtrain <- lgb.Dataset(\n  data.matrix(select(train[-valid_idx, ], -Frequency, -Exposure)),\n  label = train$Frequency[-valid_idx],\n  weight = train$Exposure[-valid_idx],\n  categorical_feature = c(\"VehBrand\", \"VehGas\", \"Region\")\n)\n\ndvalid <- lgb.Dataset.create.valid(\n  dtrain,\n  data.matrix(select(train[ valid_idx, ], -Frequency, -Exposure)),\n  label = train$Frequency[ valid_idx],\n  weight = train$Exposure[ valid_idx]\n)\n\n# model parameters\nparams_lgb <- list(\n  objective = \"poisson\",\n  learning_rate = 0.03188002,\n  num_leaves = 30,\n  reg_lambda = 0.004201069,\n  reg_alpha = 0.2523909,\n  colsample_bynode = 0.5552524,\n  subsample = 0.5938199,\n  min_child_samples = 9,\n  min_split_gain = 0.3920509,\n  poisson_max_delta_step = 0.8039541\n)\n\nset.seed(42)\nfit_lgb <- lgb.train(\n  params = params_lgb,\n  data = dtrain,\n  nrounds = 1000L,\n  valids = list(eval = dvalid),\n  early_stopping_round = 50L,\n  verbose = -1L\n)\n\nsummary(fit_lgb)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLightGBM Model (402 trees)\nObjective: poisson\nFitted to dataset with 7 columns\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# evaluate fitted model\npred_fit_lgb <- predict(\n  fit_lgb, data.matrix(select(test, -Frequency, -Exposure))\n)\n\ndeviance <- mean_poisson_deviance(\n  y_true = test$Frequency,\n  y_pred = pred_fit_lgb,\n  sample_weight = test$Exposure\n)\ncat(\"Mean Poisson Deviance:\", deviance)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMean Poisson Deviance: 0.4655023\n```\n\n\n:::\n:::\n\n\n### Surrogate Modeling\n\nWe use `{midr}` to replicate the LightGBM model.\nBy including interaction terms in the model formula, we allow the surrogate to capture the joint relationships that the GBM has learned.\nThe goal is to approximate the LightGBM function $f_{LGB}(\\mathbf{x})$ with our interpretable structure $g(\\mathbf{x})$:\n\n$$\nf_{LGB}(\\mathbf{x}) \\approx g(\\mathbf{x}) = g_\\emptyset + \\sum_{j} g_j(x_j) + \\sum_{j < k} g_{jk}(x_j, x_k)\n$$\n\n::: {.callout-warning}\n### Computational Considerations\nIncluding all second-order interactions using the `(...)^2` syntax results in $p(p-1)/2$ interaction terms.\nFor high-dimensional data, this can be memory-intensive.\nUsers should ensure sufficient RAM is available or consider limiting the formula to the most relevant features, or using a subset of the training set.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmid_lgb <- interpret(\n  Frequency ~ (VehPower + VehAge + DrivAge + LogDensity +\n               VehBrand + VehGas + Region)^2,\n  data = train,\n  lambda = 0.01,\n  weights = Exposure,\n  link = \"log\",\n  model = fit_lgb,\n  pred.fun = function(model, data) {\n    newdata <- data.matrix(select(data, -Frequency, -Exposure))\n    predict(model, newdata)\n  }\n)\n\nsummary(mid_lgb)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\ninterpret(formula = Frequency ~ (VehPower + VehAge + DrivAge +\n LogDensity + VehBrand + VehGas + Region)^2, data = train,\n model = fit_lgb, pred.fun = function(model, data) {\n newdata <- data.matrix(select(data, -Frequency, -Exposure))\n predict(model, newdata)\n }, weights = Exposure, lambda = 0.01, link = \"log\")\n\nLink: log\n\nUninterpreted Variation Ratio:\n working response \n0.071642 0.181512 \n\nWorking Residuals:\n     Min       1Q   Median       3Q      Max \n-0.51124 -0.04431 -0.00326  0.03899  3.63211 \n\nEncoding:\n           main.effect interaction\nVehPower     linear(9)   linear(5)\nVehAge      linear(18)   linear(5)\nDrivAge     linear(25)   linear(5)\nLogDensity  linear(25)   linear(5)\nVehBrand     factor(6)   factor(6)\nVehGas       factor(2)   factor(2)\nRegion       factor(7)   factor(7)\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# evaluate fitted surrogate\npred_mid_lgb = predict(mid_lgb, test, type = \"response\")\n\ndeviance <- mean_poisson_deviance(\n  y_true = test$Frequency,\n  y_pred = pred_mid_lgb,\n  sample_weight = test$Exposure\n)\ncat(\"Mean Poisson Deviance:\", deviance)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMean Poisson Deviance: 0.4670904\n```\n\n\n:::\n:::\n\n\n### Model Fidelity\n\nTo measure how successfully our surrogate replicates the LightGBM model, we use the R-squared score on the link scale ($\\log$ scale). \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# calculate R-squared on testing dataset\nR2_mid <- weighted.loss(\n  x = log(pred_fit_lgb),\n  y = log(pred_mid_lgb),\n  w = test$Exposure,\n  method = \"r2\"\n)\n\ncat(sprintf(\"R-squared: %.4f\", R2_mid))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nR-squared: 0.9295\n```\n\n\n:::\n:::\n\n\n### Feature Effects\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar.midr(mfrow = c(2, 4))\nmid.plots(mid_lgb, engine = \"graphics\", ylab = \"Partial Effect\")\n```\n\n::: {.cell-output-display}\n![](demo_r_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\nA key advantage of `{midr}` is its ability to isolate interaction effects $g_{jk}$ from main effects $g_j$.\nThis is particularly useful to understand the joint impact of two variables (e.g., `Region` and `LogDensity`).\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngrid.arrange(\n  nrow = 1, widths = c(3, 2),\n  ggmid(mid_lgb, \"LogDensity:Region\", type = \"data\",\n        data = train[1:1e4, ]) +\n    labs(y = NULL, subtitle = \"Interaction Effect\") +\n    theme(legend.position = \"bottom\"),\n  ggmid(mid_lgb, \"LogDensity:Region\", main.effects = TRUE) +\n    labs(y = NULL, subtitle = \"Total Effect\") +\n    scale_y_discrete(labels = NULL) +\n    theme(legend.position = \"bottom\")\n)\n```\n\n::: {.cell-output-display}\n![](demo_r_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar.midr(mar = c(1, 0, 1, 0), mfrow = c(1, 2))\npersp(mid_lgb, \"DrivAge:LogDensity\", theta = 45, phi = 40)\npersp(mid_lgb, \"LogDensity:Region\", theta = -45, phi = 40)\n```\n\n::: {.cell-output-display}\n![](demo_r_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n### Effect Importance\n\nTo rank the influence of each component discovered in the LightGBM model, we calculate the Effect Importance, defined as the average absolute contribution.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nimp_lgb <- mid.importance(mid_lgb, data = train, max.nrow = 2000)\ngrid.arrange(\n  nrow = 1, widths = c(4, 3),\n  ggmid(imp_lgb, theme = \"bluescale@qual\", max.nterms = 20) +\n    labs(title = \"Effect Importance\",\n         subtitle = \"Average absolute effect per feature\") +\n    theme(legend.position = \"none\"),\n  ggmid(imp_lgb, type = \"beeswarm\", theme = \"mako@div\", max.nterms = 20) +\n    labs(title = \"\",\n         subtitle = \"Distribution of effect per feature\") +\n    scale_y_discrete(labels = NULL) +\n    theme(legend.position = \"none\")\n)\n```\n\n::: {.cell-output-display}\n![](demo_r_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n### Conditional Expectation\n\nWe further explore the model's behavior using the ICE plot.\nIn the MID framework, the variation in ICE curves for a feature $j$ is explicitly governed by the interaction terms $g_{jk}$ identified from the LightGBM model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nice_lgb_link <- mid.conditional(mid_lgb, type = \"link\", variable = \"DrivAge\")\nice_lgb <- mid.conditional(mid_lgb, variable = \"DrivAge\")\ngrid.arrange(\n  nrow = 1,\n  ggmid(ice_lgb_link, var.color = LogDensity) +\n    theme(legend.position = \"bottom\") +\n    labs(y = \"Linear Predictor\",\n         title = \"Conditional Expectation\",\n         subtitle = \"Change in linear predictor\"),\n  ggmid(ice_lgb, type = \"centered\", var.color = LogDensity) +\n    theme(legend.position = \"bottom\") +\n    labs(y = \"Prediction\", title = \"\",\n         subtitle = \"Centered change in original scale\")\n)\n```\n\n::: {.cell-output-display}\n![](demo_r_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n### Additive Attribution\n\nFinally, we perform an Additive Breakdown for individual predictions.\nThis provides an exact allocation of the LightGBM's prediction into the terms of our surrogate model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(42)\nrow_ids <- sort(sample(nrow(train), 4))\n\nbd_list <- lapply(\n  row_ids,\n  function(x) {\n    res <- mid.breakdown(mid_lgb, train, row = x,\n                         format = c(\"%.6s\", \"%.3s, %.3s\"))\n    structure(res, row_id = x)\n  }\n)\n\nbd_plots <- lapply(\n  bd_list, function(x) {\n    label <- paste0(\"Breakdown of Row \", attr(x, \"row_id\"))\n    ggmid(x, theme = \"shap\", max.nterms = 10) +\n      labs(x = \"Linear Predictor\", subtitle = label) +\n      theme(legend.position = \"none\")\n  }\n)\n\ngrid.arrange(grobs = bd_plots)\n```\n\n::: {.cell-output-display}\n![](demo_r_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n## Conclusion\n\nIn this notebook, we have demonstrated how **Maximum Interpretation Decomposition (MID)** bridges the gap between predictive performance and model transparency.\nBy using the `{midr}` package, we successfully transformed a complex LightGBM model into a structured, additive representation.\n\nWhile the surrogate model fidelity may not always be perfect, the crucial advantage lies in our ability to quantify its limitations. \nThrough the **uninterpreted variation ratio**, we can directly assess the complexity of the black-box model.\nIf the fidelity is lower than expected, it serves as a diagnostic signal that the original model relies on high-order interactions or structural complexities that extend beyond second-order effects.\n\nKnowing the extent of this \"unexplained\" variance is far more valuable than operating in the dark.\nIt allows actuaries to make informed decisions about whether the additional complexity of a black-box model is justified by its performance, or if a more transparent structure is preferable for regulatory and risk management purposes.\n\nAs machine learning models become increasingly prevalent in insurance pricing and reserving, tools like MID will be essential for ensuring that our \"black-boxes\" remain accountable, reliable, and fundamentally understood.\n",
    "supporting": [
      "demo_r_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}