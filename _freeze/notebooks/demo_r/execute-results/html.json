{
  "hash": "d1722fdadd5d2ec524e30eb4795ec4a5",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Interpretation by Global Surrogate Modeling with {**midr**}\"\nsubtitle: \"Convention A | Asia\"\n---\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(arrow)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'arrow' was built under R version 4.5.2\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'arrow'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following object is masked from 'package:utils':\n\n    timestamp\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(midr)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in lapply(X = .schemes, FUN = function(x) {: strings not representable\nin native encoding will be translated to UTF-8\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(midnight)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: parsnip\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(ggplot2)\n```\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain <- read_parquet(\"../data/train.parquet\")\ntest  <- read_parquet(\"../data/test.parquet\")\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(splines)\n\nfit_glm <- glm(\n  Frequency ~ VehPower + VehAge + ns(DrivAge, df = 5) + VehBrand + VehGas + LogDensity + Region,\n  data = train,\n  weights = Exposure,\n  family = quasipoisson()\n)\n\nsummary(fit_glm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = Frequency ~ VehPower + VehAge + ns(DrivAge, df = 5) + \n    VehBrand + VehGas + LogDensity + Region, family = quasipoisson(), \n    data = train, weights = Exposure)\n\nCoefficients:\n                                   Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                       -1.922742   0.098497 -19.521  < 2e-16 ***\nVehPower                           0.030288   0.005801   5.221 1.78e-07 ***\nVehAge                            -0.012916   0.002398  -5.386 7.20e-08 ***\nns(DrivAge, df = 5)1              -1.306706   0.067780 -19.279  < 2e-16 ***\nns(DrivAge, df = 5)2              -1.309012   0.080730 -16.215  < 2e-16 ***\nns(DrivAge, df = 5)3              -1.048974   0.088655 -11.832  < 2e-16 ***\nns(DrivAge, df = 5)4              -2.933995   0.176914 -16.584  < 2e-16 ***\nns(DrivAge, df = 5)5              -0.224127   0.187145  -1.198  0.23107    \nVehBrandB12                       -0.235715   0.040323  -5.846 5.05e-09 ***\nVehBrandB2                         0.011060   0.031912   0.347  0.72890    \nVehBrandB3                         0.032384   0.044682   0.725  0.46860    \nVehBrandB5                         0.156921   0.050076   3.134  0.00173 ** \nVehBrandOther                      0.038337   0.036485   1.051  0.29338    \nVehGasRegular                     -0.152496   0.023653  -6.447 1.14e-10 ***\nLogDensity                         0.102270   0.007322  13.968  < 2e-16 ***\nRegionCentre                      -0.012085   0.049034  -0.246  0.80533    \nRegionIle-de-France                0.095651   0.059853   1.598  0.11002    \nRegionPays-de-la-Loire             0.041869   0.063439   0.660  0.50927    \nRegionProvence-Alpes-Cotes-D'Azur  0.146424   0.055538   2.636  0.00838 ** \nRegionRhone-Alpes                  0.226987   0.052063   4.360 1.30e-05 ***\nRegionOther                        0.063823   0.048680   1.311  0.18983    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for quasipoisson family taken to be 1.740256)\n\n    Null deviance: 86472  on 338994  degrees of freedom\nResidual deviance: 84838  on 338974  degrees of freedom\nAIC: NA\n\nNumber of Fisher Scoring iterations: 6\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmid_glm <- interpret(\n  Frequency ~\n    DrivAge + LogDensity + VehAge + VehPower +\n    Region + VehBrand + VehGas,\n  train,\n  weights = Exposure,\n  link = \"log\",\n  model = fit_glm,\n  verbosity = 3\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n[info] model fitting started (2026-01-10 02:51:45)\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n- [debug] 338995 predictions obtained from 'model': 0.13265512, 0.09079538, 0.08235036, ...\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n- [debug] model frame with 338995 observations created\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n- [debug] 'y' values are transformed by 'link': -2.020003, -2.399147, -2.496772, ...\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n- [debug] 'terms' include 7 main effects\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n- [debug] 'k' is set to 25 for main effects\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n[info] least squares estimation initiated with 'mode' 1 and 'method' 0\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n- [debug] 92 parameters, 338995 observations, 7 centering constraints\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n[info] least squares estimation completed\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n- [debug] uninterpreted variation ratio: 0.000107208\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n- [debug] uninterpreted variation ratio (response): 0.0001247579\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n[info] model fitting successfully finished (2026-01-10 02:51:49)\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(mid_glm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\ninterpret(formula = Frequency ~ DrivAge + LogDensity + VehAge +\n VehPower + Region + VehBrand + VehGas, data = train, model = fit_glm,\n weights = Exposure, verbosity = 3, link = \"log\")\n\nLink: log\n\nUninterpreted Variation Ratio:\n   working   response \n0.00010721 0.00012476 \n\nWorking Residuals:\n       Min         1Q     Median         3Q        Max \n-0.0103322 -0.0008741 -0.0001187  0.0012507  0.0945788 \n```\n\n\n:::\n\n::: {.cell-output-display}\n![](demo_r_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nEncoding:\n           main.effect\nDrivAge     linear(25)\nLogDensity  linear(25)\nVehAge      linear(18)\nVehPower     linear(9)\nRegion       factor(7)\nVehBrand     factor(6)\nVehGas       factor(2)\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npal <- \"#004080\"\ngridExtra::grid.arrange(\n  ggmid(mid_glm, \"DrivAge\", linewidth = 1, color = pal),\n  ggmid(mid_glm, \"LogDensity\", linewidth = 1, color = pal),\n  ggmid(mid_glm, \"VehAge\", linewidth = 1, color = pal),\n  ggmid(mid_glm, \"VehPower\", linewidth = 1, color = pal)\n)\n```\n\n::: {.cell-output-display}\n![](demo_r_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar.midr(mar = c(1,1,1,1))\npersp(mid_glm, \"DrivAge:LogDensity\", theta = 135, phi = 30, col = \"#00408080\")\n```\n\n::: {.cell-output-display}\n![](demo_r_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nimp_glm <- mid.importance(mid_glm, max.nrow = 2000)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nnumber of observations exceeds 'max.nrow': a sample of 2000 observations from 'data' is stored\n```\n\n\n:::\n\n```{.r .cell-code}\nggmid(imp_glm, \"bee\", theme = \"viridis_r\") + theme_midr(\"y\")\n```\n\n::: {.cell-output-display}\n![](demo_r_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n### GBM\nX_train <- data.matrix(\n  train |> dplyr::select(-Frequency, -Exposure)\n)\n\nX_test  <- data.matrix(\n  test  |> dplyr::select(-Frequency, -Exposure)\n)\n\nlibrary(lightgbm)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'lightgbm' was built under R version 4.5.2\n```\n\n\n:::\n\n```{.r .cell-code}\nparams_lgb <- list(\n  objective = \"poisson\",\n  learning_rate = 0.02,\n  num_leaves = 31,\n  reg_lambda = 0,\n  reg_alpha = 2,\n  colsample_bynode = 0.8,\n  subsample = 0.8,\n  min_child_samples = 20,\n  min_split_gain = 0.1,\n  poisson_max_delta_step = 0.1\n)\n\nfit_lgb <- lightgbm(\n  data = X_train,\n  label = train$Frequency,\n  weights = train$Exposure,\n  params = params_lgb,\n  nrounds = 200L,\n  verbose = 0L,\n  categorical_feature = c(\"VehBrand\", \"VehGas\", \"Region\")\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in .get_default_num_threads(): Optional package 'RhpcBLASctl' not\nfound. Detection of CPU cores might not be accurate.\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(fit_lgb)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLightGBM Model (200 trees)\nObjective: poisson\nFitted to dataset with 7 columns\n```\n\n\n:::\n\n```{.r .cell-code}\nfitted_values_lgb <- get.yhat(fit_lgb, X_train)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmid_lgb <- interpret(\n  Frequency ~ (. - Exposure)^2,\n  data = train,\n  weights = Exposure,\n  link = \"log\",\n  model = fit_lgb,\n  pred.fun = function(model, newdata) fitted_values_lgb,\n  verbosity = 3,\n  lambda = .05\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n[info] model fitting started (2026-01-10 02:52:10)\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n- [debug] 338995 predictions obtained from 'model': 0.11716635, 0.08585971, 0.07847172, ...\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n- [debug] model frame with 338995 observations created\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n- [debug] 'y' values are transformed by 'link': -2.144161, -2.455041, -2.545017, ...\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n- [debug] 'terms' include 7 main effects and 21 interactions\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n- [debug] 'k' is set to 25 for main effects and 5 for interactions\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n[info] least squares estimation initiated with 'mode' 1 and 'method' 0\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n- [debug] 610 parameters, 338995 observations, 217 centering constraints, 677 smoothing constraints\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n[info] least squares estimation completed\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n- [debug] uninterpreted variation ratio: 0.06028539\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n- [debug] uninterpreted variation ratio (response): 0.2397887\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n[info] model fitting successfully finished (2026-01-10 02:53:44)\n```\n\n\n:::\n\n```{.r .cell-code}\n# required 10 GiB\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(mid_lgb)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\ninterpret(formula = Frequency ~ (. - Exposure)^2, data = train,\n model = fit_lgb, pred.fun = function(model, newdata) fitted_values_lgb,\n weights = Exposure, verbosity = 3, link = \"log\", lambda = 0.05)\n\nLink: log\n\nUninterpreted Variation Ratio:\n working response \n0.060285 0.239789 \n\nWorking Residuals:\n     Min       1Q   Median       3Q      Max \n-0.53975 -0.04373 -0.00305  0.03957  4.21130 \n```\n\n\n:::\n\n::: {.cell-output-display}\n![](demo_r_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nEncoding:\n           main.effect interaction\nVehPower     linear(9)   linear(5)\nVehAge      linear(18)   linear(5)\nDrivAge     linear(25)   linear(5)\nVehBrand     factor(6)   factor(6)\nVehGas       factor(2)   factor(2)\nLogDensity  linear(25)   linear(5)\nRegion       factor(7)   factor(7)\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngridExtra::grid.arrange(\n  ggmid(mid_lgb, \"DrivAge\", linewidth = 1, color = pal),\n  ggmid(mid_lgb, \"LogDensity\", linewidth = 1, color = pal),\n  ggmid(mid_lgb, \"VehAge\", linewidth = 1, color = pal),\n  ggmid(mid_lgb, \"VehPower\", linewidth = 1, color = pal)\n)\n```\n\n::: {.cell-output-display}\n![](demo_r_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrotate <- theme(axis.text.x = element_text(angle = 90))\ngridExtra::grid.arrange(\n  nrow = 1,\n  ggmid(mid_lgb, \"Region\") + rotate,\n  ggmid(mid_lgb, \"VehBrand\") + rotate\n)\n```\n\n::: {.cell-output-display}\n![](demo_r_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nimp_lgb <- mid.importance(mid_lgb, data = train, max.nrow = 2000)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nnumber of observations exceeds 'max.nrow': a sample of 2000 observations from 'data' is stored\n```\n\n\n:::\n\n```{.r .cell-code}\nggmid(imp_lgb, \"heatmap\")\n```\n\n::: {.cell-output-display}\n![](demo_r_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n\n```{.r .cell-code}\nggmid(imp_lgb, \"bee\", max.nterms = 15, theme = \"viridis_r\")\n```\n\n::: {.cell-output-display}\n![](demo_r_files/figure-html/unnamed-chunk-14-2.png){width=672}\n:::\n:::\n\n\n```",
    "supporting": [
      "demo_r_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}