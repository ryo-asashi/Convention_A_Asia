---
title: "Building Surrogate Models with {midr}"
---

```{r, message=FALSE, warning=FALSE}
# data manipuration
library(arrow)

# predictive modeling
library(gam)
library(lightgbm)

# surrogate modeling
library(midr)
library(midnight)

# visualization
library(ggplot2)
library(gridExtra)

# load training and testin datasets
train <- read_parquet("../data/train.parquet")
test  <- read_parquet("../data/test.parquet")
train <- train[sample(nrow(train), 50000), ]
```

## GAM: An Interpretable Model

```{r}
fit_gam <- gam(
  Frequency ~ s(VehPower) + s(VehAge) + s(DrivAge) + s(LogDensity) +
              VehBrand + VehGas + Region,
  data = train,
  weights = Exposure,
  family = quasipoisson(link = "log")
)
summary(fit_gam)
```

### Surrogate Modeling for GAM

```{r}
mid_gam <- interpret(
  Frequency ~ VehPower + VehAge + DrivAge + LogDensity +
              VehBrand + VehGas + Region,
  train,
  weights = Exposure,
  link = "log",
  model = fit_gam
)
summary(mid_gam)
```

### Evaluation of Surrogate Model Fidelity

Typically, the R-squared metrics is used to measure the fidelity of surrogate models.

In the summary of the fitted MID model, $1 - R^s$ is referred as **(Working) Uninterpreted Variation Ratio**.

We can confirm how the predictions of the MID surrogate replicates the predictions from the original GAM on the testing dataset.

```{r}
theme_set(theme_midr("xy"))
preds_df <- data.frame(
  fit_gam = predict(fit_gam, test, type = "response"),
  mid_gam = predict(mid_gam, test, type = "response")
) 
sample_id <- sample(nrow(preds_df), 2000)
p <- ggplot(preds_df[sample_id, ])
grid.arrange(
  nrow = 1,
  p +
    geom_point(aes(log(fit_gam), log(mid_gam))) +
    labs(x = "GAM", y = "MID Surrogate",
         title = "Model Fidelity", subtitle = "Linear predictor"),
  p +
    geom_point(aes(log(fit_gam), log(mid_gam))) +
    labs(x = "GAM", y = "MID Surrogate",
         title = "", subtitle = "Prediction in the original scale")
)
```

### Visualization of Effects

```{r}
par.midr(mfrow = c(2, 4))
termplot(fit_gam)
```

```{r}
par.midr(mfrow = c(2, 4))
mid.plots(mid_gam, engine = "graphics", ylab = "Partial Effect")
```

```{r}
par.midr(mar = c(1,1,1,1))
persp(mid_gam, "LogDensity:DrivAge", theta = 225, phi = 40, shade = .5)
```

### Feature Importance

```{r, message = FALSE}
imp_gam <- mid.importance(mid_gam, data = train, max.nrow = 2000)
grid.arrange(
  nrow = 1,
  ggmid(imp_gam, fill = "steelblue") +
    labs(title = "Feature Importance",
         subtitle = "Average absolute effect per feature"),
  ggmid(imp_gam, type = "beeswarm", theme = "mako@div") +
    labs(title = "",
         subtitle = "Distribution of effect per feature") +
    theme(legend.position = "none")
)
```

### Conditional Expectation

```{r, message = FALSE}
ice_gam_link <- mid.conditional(mid_gam, type = "link", variable = "DrivAge")
ice_gam <- mid.conditional(mid_gam, variable = "DrivAge")
grid.arrange(
  nrow = 1,
  ggmid(ice_gam_link, var.color = LogDensity) +
    theme(legend.position = "bottom") +
    labs(y = "Linear Predictor",
         title = "Conditional Expectation",
         subtitle = "Change in linear predictor"),
  ggmid(ice_gam, type = "centered", var.color = LogDensity) +
    theme(legend.position = "bottom") +
    labs(y = "Prediction", title = "",
         subtitle = "Centered change in original scale")
)
```

### Additive Feature Attribution

```{r}
set.seed(42)
row_ids <- sample(nrow(train), 4)
bd_list <- lapply(
  row_ids,
  function(x) {
    res <- mid.breakdown(mid_gam, train, row = x, format = "%.6s")
    structure(res, row_id = x)
  }
)
bd_plots <- lapply(
  bd_list, function(x) {
    label <- paste0("Row ID: ", attr(x, "row_id"))
    ggmid(x, theme = "shap") +
      labs(x = "Linear Predictor", subtitle = label) +
      theme(legend.position = "none")
  }
)
grid.arrange(grobs = bd_plots)
```

## LightGBM: A Black-Box Model with High Performance

